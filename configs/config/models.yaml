# ------
# MODELS
# ------

diffusion: 

  params:
    n_obs_steps: 5
    horizon: 16    
    n_action_steps: 8

  sampling:
    fps_sampling_hist: 30
    fps_sampling_chunk: 30

act:

  params:
    n_obs_steps: 1
    chunk_size: 50   
    n_action_steps: 25

  sampling:
    fps_sampling_hist: 30
    fps_sampling_chunk: 30


flowLeonardo:

  params:
    N_history: 1
    N_chunk: 100
    n_action_steps: 25

    # Vision architecture params
    vision_backbone_name: "resnet18d.ra2_in1k" # ["resnet18d.ra2_in1k" "vit_base_patch16_224.mae" "vit_base_patch14_dinov2.lvd142m" "vit_base_patch14_reg4_dinov2.lvd142m"]
    freeze_vision_backbone: True

    # Perceiver resampler params
    use_perceiver_resampler: False
    resampler_params:
      depth: 4
      dim_head: 64
      heads: 8
      num_latents: 64
      
    # Transformer encoder
    dim_model: 512
    dim_feedforward_enc: 3200
    nhead_enc: 8
    num_layers_enc: 4
    
    # FM head type
    head_type: "flow_matching_transformer" # ["mlp" "flow_matching_mlp" "flow_matching_unet" "flow_matching_transformer"]

    # Common
    use_film: True
    timestep_embed_dim: 256
    
    # Unet
    down_dims: [256, 512]
    kernel_size: 5
    n_groups: 8

    # Transformer decoder
    dim_feedforward_dec: 2048
    nhead_dec: 8
    num_layers_dec: 4

    # FM inference
    denoising_steps: 20
    ode_type: "euler" # ["euler" "runge_kutta"]
    use_fixed_src_dist: False # decide whether to start always from same source distribution during inference

  sampling:
    fps_sampling_hist: 30
    fps_sampling_chunk: 30

    
template:

  params:
    N_history: 3
    N_chunk: 50
    n_action_steps: 25

  sampling:
    fps_sampling_hist: 30
    fps_sampling_chunk: 30
